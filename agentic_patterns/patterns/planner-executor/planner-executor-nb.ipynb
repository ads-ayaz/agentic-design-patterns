{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec1a2a0",
   "metadata": {},
   "source": [
    "# PLANNER–EXECUTOR | Agentic Pattern\n",
    "\n",
    "A two-role agentic pattern that separates the responsibilities of *goal decomposition* and *execution*. The Planner agent interprets a high-level task or objective and generates a structured plan—typically a sequence of sub-tasks or a hierarchy of actionable steps. The Executor agent(s) then carry out the specified tasks, reporting results back to the Planner or upstream orchestrator.\n",
    "\n",
    "## Problem Addressed\n",
    "This pattern solves the challenge of executing complex, multi-step tasks where direct execution is impractical, brittle, or cognitively burdensome for a single agent. It introduces explicit goal decomposition, allowing tasks to be broken down into manageable units that can be executed in parallel or sequentially. The pattern mirrors human workflows involving strategic planning and tactical implementation.\n",
    "\n",
    "## Pattern Structure\n",
    "\n",
    "- **Agents |**\n",
    "  - `Planner`: Decomposes the high-level task into a sequence of actionable sub-tasks or goals.\n",
    "  - `Executor`: Receives sub-tasks and executes them, returning results to the Planner or upstream coordinator.\n",
    "\n",
    "- **Coordination Topology |**\n",
    "  - One-way or bi-directional flow.\n",
    "  - Planner → Executor(s): task assignment.\n",
    "  - Executor → Planner: result reporting, error signaling, or clarification requests (optional).\n",
    "\n",
    "## Assumptions\n",
    "\n",
    "- The Planner is assumed to:\n",
    "  - Possess reasoning capabilities and task decomposition heuristics.\n",
    "  - Understand task requirements and suitable delegation strategies.\n",
    "\n",
    "- The Executor is assumed to:\n",
    "  - Be capable of interpreting discrete sub-tasks and executing them autonomously.\n",
    "  - Have access to relevant tools or environments needed to complete the assigned work.\n",
    "\n",
    "## Inputs\n",
    "- A high-level goal, objective, or user instruction.\n",
    "- Optionally: constraints, context, or resource information.\n",
    "\n",
    "## Outputs\n",
    "- Final result assembled from the execution of all sub-tasks.\n",
    "- Optionally: plan metadata, partial results, or execution logs.\n",
    "\n",
    "## Behavioural Flow\n",
    "\n",
    "1. User or orchestrator submits a goal to the Planner.\n",
    "2. Planner interprets the goal and decomposes it into one or more sub-tasks.\n",
    "3. Planner dispatches sub-tasks to one or more Executors.\n",
    "4. Executors complete tasks and return results.\n",
    "5. Planner (or orchestrator) assembles final output.\n",
    "\n",
    "## Strengths\n",
    "- Supports long-horizon or open-ended task execution.\n",
    "- Enables specialization between strategic reasoning and tactical action.\n",
    "- Facilitates retry, parallelism, and dynamic re-planning.\n",
    "\n",
    "## Weaknesses\n",
    "- Planner failures can undermine the whole process.\n",
    "- Requires well-formed interfaces between Planner and Executors.\n",
    "- May overcomplicate simple tasks if used prematurely.\n",
    "\n",
    "## Variations and Extensions\n",
    "- **Planner–Worker–Validator**: Adds validation loop for sub-task results.\n",
    "- **Recursive Planner**: Planner delegates to sub-planners at each level of decomposition.\n",
    "- **Distributed Executors**: Planner assigns tasks based on capability or routing rules.\n",
    "\n",
    "## Example Use Cases\n",
    "- Writing a multi-section report with different agents handling each section.\n",
    "- Executing a multi-step data processing pipeline.\n",
    "- Carrying out long-horizon research or investigative tasks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f316c362",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d776d14",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "\n",
    "This cell loads environment variables from a `.env` file using `python-dotenv`. These variables configure model selection and API access.\n",
    "\n",
    "**Required:**\n",
    "- `OPENAI_API_KEY` – for authenticating with the OpenAI API.\n",
    "\n",
    "**Optional:**\n",
    "- `CONF_OPENAI_DEFAULT_MODEL` – sets the default model for agents (e.g., `openai/gpt-4o-mini`).\n",
    "- `SERPER_API_KEY` – used for web search tools (if enabled later). You can get an API key at [serper.dev](https://serper.dev/api-keys).\n",
    "\n",
    "Loading these from `.env` keeps sensitive data out of the notebook and makes configuration flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f6cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "agent_model_DEFAULT = os.getenv('CONF_OPENAI_DEFAULT_MODEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef5fa87",
   "metadata": {},
   "source": [
    "### Agent configuration setup\n",
    "\n",
    "These two cells create a temporary folder and write the `agents-config.yaml` file used to configure agents used in the Planner–Executor pattern.\n",
    "\n",
    "Defining agents in YAML allows clear separation of roles, responsibilities, and model parameters. This makes it easier to update agent behavior without changing Python code, and ensures the system is easy to test, debug, and reproduce.\n",
    "\n",
    "Each agent is defined with:\n",
    "- `name` – for traceability\n",
    "- `instructions` – its full role prompt and behavioral expectations\n",
    "- `model`, `temperature`, `max_tokens` – (optional) controls for generation style and limits\n",
    "- `output_type` – (optional) the pydantic schema class that the agent is expected to return\n",
    "- `tools` – (optional) a list of tool names the agent can use (if any)\n",
    "\n",
    "In this pattern:\n",
    "- The **Planner** decomposes a user goal into atomic tasks with dependencies and success criteria.\n",
    "- The **Executor** uses a tool to orchestrate task execution and return the final result.\n",
    "- The **Worker** executes a single task, optionally using a web search tool when essential.\n",
    "\n",
    "Keep this config version-controlled to support reproducible experiments and easy role iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb26d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef012398",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./tmp/agents-config.yaml\n",
    "# agents-config.yaml\n",
    "planner:\n",
    "  name: Basic Planner\n",
    "  instructions: |\n",
    "    You are the Planner Agent in a Planner–Executor–Worker architecture. Your role is to interpret a user's high-level goal and decompose it into a structured plan—a sequence of clearly defined, actionable tasks that can be executed independently.\n",
    "\n",
    "    ---\n",
    "    ### Your Responsibilities\n",
    "\n",
    "    1. Read and interpret the user's high-level goal.\n",
    "    2. Break it into a set of well-scoped, atomic tasks.\n",
    "    3. Define clear **success criteria** for each task—these are objective conditions that a Worker agent can use to determine whether the task was successfully completed.\n",
    "    4. Identify any task dependencies. A task can list other task IDs as prerequisites in its `inputs` field.\n",
    "    5. Provide any execution hints or assumptions in the `notes` field.\n",
    "    6. Design the plan so that the **final output** can be returned directly from one of the last tasks. The Executor will not synthesize results—it will forward the final output from the appropriate task(s).\n",
    "\n",
    "    ---\n",
    "    ### Task Structure\n",
    "\n",
    "    Each task in your plan must include:\n",
    "    - `id`: Unique task identifier (e.g., task-001).\n",
    "    - `instructions`: The specific action to be performed by a Worker.\n",
    "    - `inputs`: A list of task IDs whose outputs are required before this task can run.\n",
    "    - `success_criteria`: An objective condition that determines whether the task is complete and correct.\n",
    "    - `notes`: (Optional) Constraints, formatting guidance, or clarifications for the Worker.\n",
    "\n",
    "    ---\n",
    "    ### Behavioral Expectations\n",
    "\n",
    "    - Your role is to design the plan, not to execute tasks.\n",
    "    - Avoid redundancy or unnecessary decomposition.\n",
    "    - Ensure the final output of the system will be the result of one of the terminal tasks.\n",
    "\n",
    "    You are the strategic planner. Your output enables the rest of the system to fulfill the user’s request.\n",
    "  model: openai/gpt-4o-mini\n",
    "  has_memory: False\n",
    "  temperature: 0.4\n",
    "  max_tokens: 1000\n",
    "  output_type: TasksPlan\n",
    "  \n",
    "executor:\n",
    "  name: Goal Fulfillment Executor\n",
    "  instructions: |\n",
    "    You are the Executor Agent in a Planner–Executor–Worker architecture.\n",
    "\n",
    "    Your role is to fulfill a Planner-defined goal by executing a structured plan using the provided tool, then returning the final result based on the output of one or more **final tasks**.\n",
    "\n",
    "    ---\n",
    "    ### Responsibilities:\n",
    "\n",
    "    1. Read the Planner's `goal` to understand the desired outcome.\n",
    "    2. Use the `orchestrate_tasks` tool to execute the full task plan.\n",
    "       - This will run tasks in correct order using dependency resolution.\n",
    "       - Each task is executed by a Worker agent.\n",
    "    3. Identify the task(s) at the **end of the plan** (i.e., those with no dependents).\n",
    "    4. Use the output of those final task(s) to form your response:\n",
    "       - If the output satisfies the goal, return it as-is.\n",
    "       - If it's incomplete, explain what's missing.\n",
    "       - If it fails to address the goal, return a failure message and reasoning.\n",
    "\n",
    "    ---\n",
    "    ### Output Format – ExecutorResponse\n",
    "\n",
    "    Return your output as:\n",
    "    - `status`: \"success\", \"partial\", or \"failed\"\n",
    "    - `final_output`: the final result string, extracted from the last task(s)\n",
    "    - `reasoning`: optional explanation (required if partial or failed)\n",
    "\n",
    "    ---\n",
    "    ### Guidelines\n",
    "\n",
    "    - Do not inspect or return intermediate task outputs.\n",
    "    - Do not synthesize across tasks unless absolutely necessary.\n",
    "    - The system depends on the Planner to ensure that a final task produces the final user-facing output.\n",
    "\n",
    "    You are the final fulfillment agent. Return the final task result if it satisfies the Planner's goal.\n",
    "  model: openai/gpt-4o\n",
    "  has_memory: False\n",
    "  temperature: 0.3\n",
    "  max_tokens: 10000\n",
    "  tools:\n",
    "    - orchestrate_tasks\n",
    "  output_type: ExecutorResponse\n",
    "\n",
    "worker:\n",
    "  name: Task Worker\n",
    "  instructions: |\n",
    "    You are a Worker Agent in a Planner–Executor–Worker system. Your job is to execute a single atomic task as defined by a Planner and assigned by an Executor.\n",
    "\n",
    "    ---\n",
    "    ### Your Task Inputs:\n",
    "    - `instructions`: What to do.\n",
    "    - `inputs`: Data or outputs from dependent tasks.\n",
    "    - `notes`: Optional hints, assumptions, or constraints.\n",
    "    - `success_criteria`: How to judge whether the task was successfully completed.\n",
    "\n",
    "    ---\n",
    "    ### Tool Use Policy\n",
    "\n",
    "    You have access to a `web_search_tool` that performs a real-time internet search.\n",
    "\n",
    "    Use this tool **only when strictly necessary**—specifically:\n",
    "    - If the task instructions **explicitly require** recent or external information.\n",
    "    - If you have **reasoned through the task** and cannot answer it using internal knowledge or inputs.\n",
    "\n",
    "    **Do not use the tool by default.** Most tasks should be answerable without it.\n",
    "\n",
    "    You are allowed to invoke the tool **no more than once per task**. If the result is insufficient, proceed with your best answer using the available information.\n",
    "\n",
    "    Think before you search. Your efficiency and accuracy depend on it.\n",
    "    \n",
    "    ---\n",
    "    ### What You Must Do:\n",
    "    1. Read and understand the instructions.\n",
    "    2. Use the inputs as needed to complete the task.\n",
    "    3. Follow the notes and apply relevant constraints.\n",
    "    4. Reason carefully about whether external information is needed. Use the `web_search_tool` only if it’s essential to fulfill the task accurately.\n",
    "    5. Ensure your output clearly meets the success criteria.\n",
    "\n",
    "    ---\n",
    "    ### Your Output:\n",
    "    Return a single response that fulfills the task instructions.\n",
    "    - Be direct and informative.\n",
    "    - Do not return success/failure flags—just the result.\n",
    "    - Do not speculate or re-interpret the task.\n",
    "\n",
    "    You are a focused, efficient task executor. Think before you search. Execute with precision.\n",
    "  model: openai/gpt-4o-mini\n",
    "  has_memory: False\n",
    "  temperature: 0.3\n",
    "  max_tokens: 5000\n",
    "  tools:\n",
    "    - web_search_tool\n",
    "  output_type: TaskOutput\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45db470b",
   "metadata": {},
   "source": [
    "### Output schema definitions\n",
    "\n",
    "This cell defines the **structured output classes** expected from each agent using `pydantic`. These schemas ensure type safety, enforce structure, and help downstream components validate and process responses.\n",
    "\n",
    "#### Key Classes:\n",
    "- `PlannerTask` – Represents a single task defined by the Planner, with fields for instructions, dependencies, success criteria, and optional notes.\n",
    "- `TasksPlan` – The Planner's full output: a user-aligned goal and a sequence of structured tasks.\n",
    "- `TaskOutput` – Captures a single Worker result, including the output and any execution errors.\n",
    "- `OrchestratorResponse` – Used by the Executor's tool to return results from executing all tasks.\n",
    "- `ExecutorResponse` – The final system output: includes a status flag, a synthesized or extracted response, and optional reasoning.\n",
    "\n",
    "Each class uses field-level descriptions that align with agent instructions, ensuring schema expectations and role behavior remain in sync.\n",
    "\n",
    "#### Output Registry\n",
    "The `output_registry` dictionary maps class names to classes so the correct schema can be dynamically loaded based on the `output_type` string defined in each agent’s YAML config.\n",
    "\n",
    "This decouples the agent configuration from the implementation and simplifies agent creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aab143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define structured output types for Planner\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, Literal, Optional\n",
    "\n",
    "class PlannerTask(BaseModel):\n",
    "    id: str = Field(..., pattern=r'^task-\\d{3}$', description='Unique, sequential task ID (e.g., task-001, task-002)')\n",
    "    instructions: str = Field(..., description='Specific instruction to be passed to an Executor.')\n",
    "    success_criteria: str = Field(..., description='An objective condition or check that defines what it means for this task to be successfully completed.')\n",
    "    inputs: list[str] = Field(default_factory=list, description='List any task dependencies (task IDs) or required outputs from other tasks.')\n",
    "    notes: Optional[str] = Field(None, description='Optional field for hints, assumptions, or constraints.')\n",
    "\n",
    "class TasksPlan(BaseModel):\n",
    "    goal: str = Field(..., description='Your interpretation of the original objective.'),\n",
    "    plan: list[PlannerTask] = Field(default_factory=list, description='Set of tasks that collectively fulfill the objective.')\n",
    "\n",
    "\n",
    "# Define structured output types for Orchestrator\n",
    "\n",
    "class TaskOutput(BaseModel):\n",
    "    id: str = Field(..., description='Task ID of executed task.')\n",
    "    output: str = Field(None, description='Output result from executing the task.')\n",
    "    errors: Optional[str] = Field(None, description='Description of errors encountered (if any) while executing the task.')\n",
    "\n",
    "class OrchestratorResponse(BaseModel):\n",
    "    tasks_executed: Dict[str,TaskOutput] = Field(default_factory=dict, description='Outputs from executed tasks.')\n",
    "    # tasks_executed: list[TaskOutput] = Field(default_factory=list, description='Outputs from executed tasks.')\n",
    "\n",
    "\n",
    "# Define the structured output for the Executor\n",
    "\n",
    "class ExecutorResponse(BaseModel):\n",
    "    status: Literal[\"success\", \"partial\", \"failed\"]\n",
    "    final_output: str = Field(None, description=\"The best response to the Planner's goal synthesized from the task results.\")\n",
    "    reasoning: Optional[str] = Field(None, description=\"Explanation in case you return a 'partial' or 'failed' status.\")\n",
    "    # task_outputs: list[TaskOutput] = Field(..., description='Outputs from executed tasks.')\n",
    "\n",
    "\n",
    "\n",
    "output_registry = {cls.__name__: cls for cls in [\n",
    "    ExecutorResponse,\n",
    "    OrchestratorResponse,\n",
    "    PlannerTask,\n",
    "    TaskOutput,\n",
    "    TasksPlan,\n",
    "]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d9e034",
   "metadata": {},
   "source": [
    "### Load agent configuration\n",
    "\n",
    "This cell reads the `agents-config.yaml` file and parses it into a Python dictionary. The result is printed as formatted JSON to verify that the agent definitions loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d69b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the agents-config.yaml file\n",
    "\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "with open('./tmp/agents-config.yaml', 'r') as file:\n",
    "    agent_config_data = yaml.safe_load(file)\n",
    "\n",
    "formatted_json = json.dumps(agent_config_data, indent=4)\n",
    "print(formatted_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26256c81",
   "metadata": {},
   "source": [
    "### Tool definitions\n",
    "\n",
    "This cell defines two tools used by agents in the Planner–Executor–Worker pattern and registers them in a `tool_registry` so they can be referenced dynamically from YAML.\n",
    "\n",
    "Each tool is wrapped with the `@function_tool` decorator to expose it to agents. The `tool_registry` maps tool names (as defined in YAML) to the actual function objects used at runtime.\n",
    "\n",
    "#### 🔄 `orchestrate_tasks`\n",
    "\n",
    "Used by the **Executor**, this tool receives a `TasksPlan` and:\n",
    "1. Builds a task graph using `inputs` as dependencies.\n",
    "2. Executes tasks in parallel when possible.\n",
    "3. Waits to run dependent tasks until their inputs are resolved.\n",
    "4. Uses `assign_task()` to call a Worker agent with fully prepared task context.\n",
    "5. Tracks and stores each output in `OrchestratorResponse.tasks_executed`.\n",
    "\n",
    "It ensures correct execution order and returns a complete set of results for the plan.\n",
    "\n",
    "#### 🌐 `web_search_tool`\n",
    "\n",
    "Used by **Workers** to perform real-time internet searches via the Serper API.  \n",
    "The tool sends a query and returns JSON search results (or `None` if an error occurs).  \n",
    "Workers are instructed to use this tool sparingly and only when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d911d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import requests\n",
    "from agents import Runner, function_tool, trace\n",
    "from collections import defaultdict\n",
    "from typing import Any, Dict, Set\n",
    "\n",
    "@function_tool\n",
    "async def orchestrate_tasks(task_plan: TasksPlan) -> OrchestratorResponse:\n",
    "    \"\"\"\n",
    "    Pass a plan of tasks to an orchastrator for execution and receive the results of all executed tasks.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Started orchestrate_tasks tool\")\n",
    "    if task_plan is None:\n",
    "        raise ValueError(\"Cannot orchestrate an empty task plan.\")\n",
    "\n",
    "    completed = OrchestratorResponse()\n",
    "    if len(task_plan.plan) < 1:\n",
    "        return completed\n",
    "\n",
    "    print(f\"There are {len(task_plan.plan)} tasks in the plan.\")\n",
    "    task_map = {task.id: task for task in task_plan.plan}\n",
    "    running: Set[str] = set()\n",
    "    dependents = defaultdict(list)\n",
    "    dependency_count = {task.id: len(task.inputs) for task in task_plan.plan}\n",
    "\n",
    "    # Build reverse dependency map\n",
    "    for task in task_plan.plan:\n",
    "        for dep in task.inputs:\n",
    "            dependents[dep].append(task.id)\n",
    "\n",
    "    # Track tasks ready to run (no unresolved dependencies)\n",
    "    ready = [task_id for task_id, count in dependency_count.items() if count == 0]\n",
    "\n",
    "    async def run_task(task_id: str):\n",
    "        print(f\"running {task_id}\")\n",
    "        task = task_map[task_id]\n",
    "        resolved_inputs = {dep: completed.tasks_executed[dep] for dep in task.inputs}\n",
    "        prompt = (\n",
    "            f\"Task Instructions:\\n{task.instructions}\\n\\n\"\n",
    "            f\"Success Criteria:\\n{task.success_criteria}\\n\\n\"\n",
    "            f\"Inputs:\\n{resolved_inputs if resolved_inputs else 'None'}\\n\\n\"\n",
    "            f\"Notes:\\n{task.notes or 'None'}\"\n",
    "        )\n",
    "        result = await assign_task(prompt)\n",
    "        completed.tasks_executed[task_id] = result\n",
    "        print(f\"completed {task_id}\")\n",
    "\n",
    "        # Mark dependents as potentially ready\n",
    "        for dependent in dependents[task_id]:\n",
    "            dependency_count[dependent] -= 1\n",
    "            if dependency_count[dependent] == 0:\n",
    "                ready.append(dependent)\n",
    "\n",
    "    # Task execution loop\n",
    "    while ready:\n",
    "        batch = ready.copy()\n",
    "        ready.clear()\n",
    "        tasks = [asyncio.create_task(run_task(task_id)) for task_id in batch]\n",
    "        for coro in asyncio.as_completed(tasks):\n",
    "            await coro\n",
    "\n",
    "    return completed\n",
    "\n",
    "@function_tool\n",
    "def web_search_tool(query: str, timeout: int = 10) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Performs a web search using the Google Serper API.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query string.\n",
    "        timeout (int): The number of seconds to wait for a response from the server.\n",
    "\n",
    "    Returns:\n",
    "        Optional[Dict[str, Any]]: A dictionary containing the JSON response from the API,\n",
    "                                  or None if an error occurs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate API key\n",
    "    api_key = os.getenv('SERPER_API_KEY')\n",
    "    if not api_key:\n",
    "        print(\"Error: SERPER_API_KEY environment variable not set.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    with requests.Session() as session:\n",
    "        url = \"https://google.serper.dev/search\"\n",
    "\n",
    "        headers = {\n",
    "            'X-API-KEY': api_key,\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "\n",
    "        print(f\"web_search_tool: {query}\")\n",
    "        payload = {\"q\": query}\n",
    "\n",
    "        try:\n",
    "            response = session.post(url, headers=headers, json=payload, timeout=timeout)\n",
    "\n",
    "            # Check for successful HTTP status code\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            return response.json()\n",
    "\n",
    "        except requests.exceptions.HTTPError as http_err:\n",
    "            print(f\"HTTP error occurred: {http_err}\")\n",
    "            print(f\"Response content: {response.text}\")\n",
    "        except requests.exceptions.ConnectionError as conn_err:\n",
    "            print(f\"Connection error occurred: {conn_err}\")\n",
    "        except requests.exceptions.Timeout as timeout_err:\n",
    "            print(f\"Timeout error occurred: {timeout_err}\")\n",
    "        except requests.exceptions.RequestException as req_err:\n",
    "            print(f\"An unexpected error occurred: {req_err}\")\n",
    "        except json.JSONDecodeError as json_err:\n",
    "            print(f\"Error decoding JSON response: {json_err}\")\n",
    "            print(f\"Response content: {response.text}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "tool_registry = {tool.name: tool for tool in [\n",
    "    orchestrate_tasks,\n",
    "    web_search_tool\n",
    "]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eb905c",
   "metadata": {},
   "source": [
    "### Instantiate agents from configuration\n",
    "\n",
    "This cell defines `create_agent()`, a utility that instantiates agents based on their definitions in `agents-config.yaml`.\n",
    "\n",
    "🔧 **How it works:**\n",
    "- Validates that the requested agent type is defined in the YAML file (e.g., planner, executor, worker).\n",
    "- Loads the model, temperature, max_tokens, and instructions from YAML.\n",
    "- Resolves `tools` and `output_type` using internal registries.\n",
    "- Prepends today's date to the agent's instructions (for context-aware prompting).\n",
    "- Optionally enables session memory via `SQLiteSession` (not used in this pattern).\n",
    "\n",
    "At the end of the cell, the Planner, Executor, and Worker agents are instantiated and ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e843c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from agents import Agent, ModelSettings, SQLiteSession\n",
    "\n",
    "def create_agent(agent_type: str = None):\n",
    "    \"\"\" \n",
    "    Creates and returns an Agent that matches the given definition in the agents-config \n",
    "    YAML file. Optionally returns a memory Session if agent configuration calls for it.\n",
    "    \"\"\"\n",
    "\n",
    "    if agent_type is None or not agent_type.strip():\n",
    "        raise ValueError(\"agent_type must be a valid type of agent defined in agent-configs.yaml.\")\n",
    "    \n",
    "    agent_config = agent_config_data.get(agent_type)\n",
    "    if agent_config is None:\n",
    "        raise ValueError(f\"'{agent_type}' does not match an agent defined in agent-configs.yaml.\")\n",
    "\n",
    "    # Generate a timestamp string for unique naming\n",
    "    now_string = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SU%s\")\n",
    "\n",
    "    # Prepare model settings\n",
    "    agent_model_settings = ModelSettings(\n",
    "        temperature=agent_config.get('temperature'),\n",
    "        max_tokens=agent_config.get('max_tokens'),\n",
    "    )\n",
    "\n",
    "    # Resolve tools from string names (if any)\n",
    "    tool_names = agent_config.get('tools', [])\n",
    "    resolved_tools = []\n",
    "    for name in tool_names:\n",
    "        tool = tool_registry.get(name)\n",
    "        if tool is None:\n",
    "            raise ValueError(f\"Tool '{name}' specified in config for agent '{agent_type}' is not registered.\")\n",
    "        resolved_tools.append(tool)\n",
    "\n",
    "    # Instantiate the agent\n",
    "    agent_name = agent_config.get('name') or f\"{agent_type}_{now_string}\"\n",
    "    agent_instructions = agent_config.get('instructions')\n",
    "    if agent_instructions is None or not agent_instructions.strip():\n",
    "        raise ValueError(f\"No instructions for '{agent_name}' have been specified in the configuration.\")\n",
    "    new_agent = Agent(\n",
    "        name=agent_name,\n",
    "        instructions=f\"Today is {datetime.now().strftime('%Y-%m-%d')}.\\n\\n{agent_instructions}\",\n",
    "        tools=resolved_tools,\n",
    "        model=agent_config.get('model') or agent_model_DEFAULT,\n",
    "        output_type=output_registry.get(agent_config.get('output_type') or None),\n",
    "        model_settings=agent_model_settings\n",
    "    )\n",
    "\n",
    "    # Create memory session for agent if configured\n",
    "    agent_has_memory = agent_config.get('has_memory') or False\n",
    "    agent_session_name = f\"{agent_name}__SESSION_{now_string}\" if agent_has_memory else None\n",
    "    agent_session = SQLiteSession(agent_session_name) if agent_session_name else None\n",
    "\n",
    "    return (new_agent, agent_session)\n",
    "\n",
    "# Instantiate the agents. We're not using memory so ignore the second return.\n",
    "planner, _ = create_agent('planner')\n",
    "executor, _ = create_agent('executor')\n",
    "worker, _ = create_agent('worker')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f45b302",
   "metadata": {},
   "source": [
    "### Assign a task to the Worker agent\n",
    "\n",
    "This cell defines the `assign_task()` function, which asynchronously routes a task prompt to the Worker agent and returns its structured output as a `TaskOutput` object. This function is used internally by the `orchestrate_tasks` tool to execute individual atomic tasks.\n",
    "\n",
    "- It uses `Runner.run()` to execute the prompt against the Worker.\n",
    "- The `enable_trace` flag controls whether the task execution is wrapped in a trace context. This is typically set to `False` because the Worker is usually called from within the Executor’s trace.\n",
    "- Tracing can be enabled manually for standalone debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797e7e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a task to a worker agent\n",
    "\n",
    "from agents import Runner, function_tool, trace\n",
    "\n",
    "# @function_tool\n",
    "async def assign_task(task: str, enable_trace: bool = False) -> TaskOutput:\n",
    "    \"\"\"\n",
    "    Asssign a task to the agent and receive its response in return.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check that Worker agent exists\n",
    "    if worker is None:\n",
    "        raise ValueError(\"Agent has not been created yet.\")\n",
    "    \n",
    "    # When calling this function standalone, set enable_trace to True\n",
    "    if enable_trace:\n",
    "        with trace(worker.name):\n",
    "            result = await Runner.run(worker, task)\n",
    "    else:\n",
    "        result = await Runner.run(worker, task)\n",
    "    \n",
    "    return result.final_output_as(TaskOutput)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f111e080",
   "metadata": {},
   "source": [
    "### Optional: Test the Worker with a sample task\n",
    "\n",
    "This cell defines a toggleable test for the `assign_task()` function. It is disabled by default to avoid unnecessary API usage and latency. Enable it to test Worker behavior.\n",
    "\n",
    "When `enable_worker_task_test` is set to `True`, it sends a sample task to the Worker agent and prints the result.\n",
    "\n",
    "🧪 **Purpose:**  \n",
    "- Verify the Worker is correctly instantiated.\n",
    "- Confirm that tool usage (like `web_search_tool`) is functioning as expected.\n",
    "- Provides a quick sanity check without running the full Planner–Executor pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c928ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_worker_task_test = False     # Set to True to run this cell\n",
    "\n",
    "if enable_worker_task_test:\n",
    "    test_task = {\n",
    "        'id': 'task-017',\n",
    "        'instructions': 'Tell me today\\'s date and list the top 10 headlines around the world. DO NOT INVENT THEM.',\n",
    "        'success_criteria': 'Response contains a valid date and lists 10 news headlines.',\n",
    "        'inputs': None\n",
    "    }\n",
    "\n",
    "    task_string = json.dumps(test_task)\n",
    "    print(task_string)\n",
    "\n",
    "    result = await assign_task(task_string, True)\n",
    "\n",
    "    if result is not None:\n",
    "       print(f\"TaskOutput:\\n{result.model_dump_json(indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb4da19",
   "metadata": {},
   "source": [
    "### Generate a task plan from a user query\n",
    "\n",
    "The next two cells define and optionally run the Planner agent to break down a high-level user query into a structured task plan. The returned plan is used by the Executor to drive downstream task execution.\n",
    "\n",
    "🔧 **`make_tasks_plan(query)`**\n",
    "- Sends the query to the Planner using `Runner.run()`.\n",
    "- Wraps the execution in a trace for observability.\n",
    "- Returns the result as a `TasksPlan` object.\n",
    "\n",
    "🧪 **Optional test**\n",
    "- The second cell allows you to test the Planner by providing a real query (disabled by default).\n",
    "- When enabled, it prints the Planner’s full task plan in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a user query\n",
    "\n",
    "from agents import Runner, function_tool, trace\n",
    "\n",
    "async def make_tasks_plan(query: str) -> TasksPlan:\n",
    "\n",
    "    # Check that Planner agent exists\n",
    "    if planner is None:\n",
    "        raise ValueError(\"Agent has not been created yet.\")\n",
    "        \n",
    "    result = None\n",
    "\n",
    "    with trace(planner.name):\n",
    "        result = await Runner.run(planner, f\"User Goal: {query}\")\n",
    "\n",
    "    return result.final_output_as(TasksPlan)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac428984",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_planner_query_test = False     # Set to True to run this cell\n",
    "\n",
    "if enable_planner_query_test:\n",
    "    q = \"\"\"Produce a briefing document summarizing the most significant developments in climate policy across the US, EU, \n",
    "        and China over the past 12 months. Include key policy changes, notable legislation, and international agreements. \n",
    "        Conclude with a comparative analysis highlighting similarities and differences.\"\"\"\n",
    "    plan = await make_tasks_plan(q)\n",
    "\n",
    "    if plan is not None:\n",
    "        print(f\"TasksPlan:\\n{plan.model_dump_json(indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4027b5bf",
   "metadata": {},
   "source": [
    "### Execute a task plan using the Executor agent\n",
    "\n",
    "These cells handle the execution of a full task plan by coordinating with the Executor agent. Running the test requires `plan` to be a valid `TasksPlan` -- just run the planner query test in the previous cell first.\n",
    "\n",
    "🧩 **`execute_tasks_plan(plan)`**\n",
    "- Accepts a `TasksPlan` (from the Planner).\n",
    "- Serializes the plan to JSON and sends it to the Executor via `Runner.run()`.\n",
    "- The Executor uses the `orchestrate_tasks` tool to run all tasks, handle dependencies, and collect final outputs.\n",
    "- Returns a structured `ExecutorResponse` with:\n",
    "  - `status`: Whether the goal was fulfilled (`success`, `partial`, `failed`)\n",
    "  - `final_output`: Synthesized response to the original user query\n",
    "  - `reasoning`: Optional, for partial/failed responses\n",
    "\n",
    "🧪 **Optional test**\n",
    "- The second cell lets you test this execution process using a previously defined `plan` (disabled by default to prevent accidental API calls).\n",
    "- If enabled, it prints the final status and output from the Executor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e722a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Runner, trace\n",
    "\n",
    "async def execute_tasks_plan(plan: TasksPlan) -> ExecutorResponse:\n",
    "\n",
    "    # Check that Planner agent exists\n",
    "    if executor is None:\n",
    "        raise ValueError(\"Agent has not been created yet.\")\n",
    "        \n",
    "    plan_str = plan.model_dump_json()\n",
    "\n",
    "    result = None\n",
    "\n",
    "    with trace(executor.name):\n",
    "        result = await Runner.run(executor, plan_str)\n",
    "\n",
    "    if result and result.final_output:\n",
    "        return result.final_output_as(ExecutorResponse)\n",
    "    else:\n",
    "        raise ValueError(\"The runner did not return a valid final_output\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec5d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_execute_tasks_plan_test = False     # Set to True to run this cell\n",
    "\n",
    "if enable_execute_tasks_plan_test:\n",
    "    if not plan:\n",
    "        raise ValueError(\"`plan` must be a valid TasksPlan to run this test\")\n",
    "\n",
    "    answer = await execute_tasks_plan(plan=plan)\n",
    "\n",
    "    if answer is not None:\n",
    "        print(f\"Result Status: {answer.status}\")\n",
    "        print(f\"Final Output:\\n{answer.final_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb348fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Runner, trace\n",
    "\n",
    "async def run(query: str) -> ExecutorResponse:\n",
    "    \n",
    "    # Check that Planner agent exists\n",
    "    if planner is None:\n",
    "        raise ValueError(\"Agent has not been created yet.\")\n",
    "        \n",
    "    # Make a plan from the user query\n",
    "    with trace(planner.name):\n",
    "        planner_result = await Runner.run(planner, f\"User Goal: {query}\")\n",
    "    if planner_result is None or not planner_result.final_output:\n",
    "        raise ValueError(\"Planner agent failed to produce a valid plan.\")\n",
    "\n",
    "    # Serialize the plan         \n",
    "    plan = planner_result.final_output_as(TasksPlan)\n",
    "    plan_str = plan.model_dump_json()\n",
    "\n",
    "    # Execute the plan\n",
    "    with trace(executor.name):\n",
    "        executor_result = await Runner.run(executor, plan_str)\n",
    "\n",
    "    if executor_result and executor_result.final_output:\n",
    "        return executor_result.final_output_as(ExecutorResponse)\n",
    "    else:\n",
    "        raise ValueError(\"The Executor did not return a valid response.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ca1708",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = [\n",
    "    \"\"\"Produce a briefing document summarizing the most significant developments in climate policy across the US, EU, \n",
    "    and China over the past 12 months. Include key policy changes, notable legislation, and international agreements. \n",
    "    Conclude with a comparative analysis highlighting similarities and differences.\n",
    "    - Unless instructed otherwise, synthesize the final output as a concise narrative document. \n",
    "    - In the final output, prefer paragraphs over lists; only use bullets and numbered lists when absolutely necessary.\n",
    "    - Format the final output as a markdown document.\n",
    "    \"\"\",\n",
    "\n",
    "    \"\"\"\n",
    "    Produce a policy profile on India's renewable energy transition over the past five years. The output should include:\n",
    "    - A timeline of major policy actions and reforms.\n",
    "    - Summary of government programs (e.g., subsidies, R&D funding).\n",
    "    - Key statistics on solar, wind, and hydro adoption.\n",
    "    - Commentary from recent policy papers and media sources.\n",
    "\n",
    "    Synthesize all findings into a single markdown document with clearly delineated sections. Use a table for the \n",
    "    timeline. Do not include citations—just summarize the most critical content.\n",
    "    \"\"\",\n",
    "\n",
    "    \"\"\"\n",
    "    Summarize the current state of the global semiconductor supply chain. Include:\n",
    "    - Major manufacturers and suppliers by region.\n",
    "    - Current geopolitical and economic risks.\n",
    "    - Recent legislation or trade agreements (past 2 years).\n",
    "    - Comparative analysis of US, Taiwan, South Korea, and China.\n",
    "\n",
    "    Present the final result as a well-structured briefing with a neutral tone. Ensure that all key claims are grounded in recent facts and avoid vague generalizations. Use paragraphs only—do not use bullet points or headings.\n",
    "    \"\"\",\n",
    "\n",
    "    \"\"\"\n",
    "    Extract and transform insights from the following workflow:\n",
    "    1. Identify five notable research papers on large language models (LLMs) from the last 18 months.\n",
    "    2. Summarize the key contributions and limitations of each paper.\n",
    "    3. Compare the approaches used and identify recurring challenges or patterns.\n",
    "\n",
    "    Produce a structured markdown report with three sections: Overview, Comparative Insights, and Conclusions. Use clear transitions between sections. Avoid technical jargon when possible.\n",
    "    \"\"\",\n",
    "\n",
    "    \"\"\" \n",
    "    Write a historical summary of the Paris Agreement: how it was formed, what it aims to achieve, and how its implementation has evolved over time. Focus on pivotal moments from 2015 to present.\n",
    "\n",
    "    Output should be a standalone markdown article. No need to break into multiple tasks unless truly necessary.\n",
    "    \"\"\",\n",
    "\n",
    "    \"\"\" \n",
    "    Evaluate how five major tech companies (e.g., Apple, Google, Microsoft, Meta, Amazon) are addressing AI ethics and responsible AI governance. For each company:\n",
    "    - Identify key public commitments, policies, or frameworks.\n",
    "    - Assess how comprehensive and enforceable their commitments appear.\n",
    "\n",
    "    Synthesize the findings into a comparative markdown report and assign a qualitative score (e.g., High, Medium, Low) to each company’s efforts. Present the final output in a table followed by a short narrative summary.\n",
    "    \"\"\",\n",
    "\n",
    "    \"\"\"\n",
    "    blah blah blah\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "q = test_query[6]\n",
    "\n",
    "answer = await run(query=q)\n",
    "\n",
    "if answer is not None:\n",
    "    print(f\"Query: {q}\")\n",
    "    print(f\"Result Status: {answer.status}\")\n",
    "    print(f\"Final Output:\\n{answer.final_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
